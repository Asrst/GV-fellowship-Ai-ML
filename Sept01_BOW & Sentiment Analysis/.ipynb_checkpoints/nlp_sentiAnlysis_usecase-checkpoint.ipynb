{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import math as m\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain = pd.read_excel(str(path)+'/nlp_train.xlsx', header = None)\n",
    "itest = pd.read_excel(str(path)+'/nlp_test.xlsx', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itrain.head()\n",
    "itrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itest.head()\n",
    "itest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg    194\n",
      "pos    192\n",
      "Name: 1, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pos    41\n",
       "neg    40\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(itrain[1].value_counts())\n",
    "itest[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itrain.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>Laugh track does not help this show in the lea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>This show is the best legal show in years. The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                               \n",
       "    count unique                                                top freq\n",
       "1                                                                       \n",
       "neg   194    194  Laugh track does not help this show in the lea...    1\n",
       "pos   192    192  This show is the best legal show in years. The...    1"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itrain.groupby(itrain[1]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Everybody loves Raymond.  The only joke here is that the idea actually found its way onto the airwaves.  In other words it\\'s just one joke less than a one joke program.  As with most sitcoms, it appeals to those with an intellectual development that was stopped at age 8.  Fortunately they did have the good sense to employ a laugh-track so that the audience will be signaled whenever something is broadcast that was intended to be funny. The program amounts to a scandalous waste of talent.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = itrain[0][1].lower().split()\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmed_words = []\n",
    "for w in words:\n",
    "    w = PorterStemmer().stem(w) \n",
    "    stemmed_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not', 'everybody', 'loves', 'raymond.', 'the', 'only', 'joke', 'here', 'is', 'that', 'the', 'idea', 'actually', 'found', 'its', 'way', 'onto', 'the', 'airwaves.', 'in', 'other', 'words', \"it\\\\'s\", 'just', 'one', 'joke', 'less', 'than', 'a', 'one', 'joke', 'program.', 'as', 'with', 'most', 'sitcoms,', 'it', 'appeals', 'to', 'those', 'with', 'an', 'intellectual', 'development', 'that', 'was', 'stopped', 'at', 'age', '8.', 'fortunately', 'they', 'did', 'have', 'the', 'good', 'sense', 'to', 'employ', 'a', 'laugh-track', 'so', 'that', 'the', 'audience', 'will', 'be', 'signaled', 'whenever', 'something', 'is', 'broadcast', 'that', 'was', 'intended', 'to', 'be', 'funny.', 'the', 'program', 'amounts', 'to', 'a', 'scandalous', 'waste', 'of', 'talent.']\n",
      "\n",
      " ['not', 'everybodi', 'love', 'raymond.', 'the', 'onli', 'joke', 'here', 'is', 'that', 'the', 'idea', 'actual', 'found', 'it', 'way', 'onto', 'the', 'airwaves.', 'in', 'other', 'word', \"it\\\\'\", 'just', 'one', 'joke', 'less', 'than', 'a', 'one', 'joke', 'program.', 'as', 'with', 'most', 'sitcoms,', 'it', 'appeal', 'to', 'those', 'with', 'an', 'intellectu', 'develop', 'that', 'wa', 'stop', 'at', 'age', '8.', 'fortun', 'they', 'did', 'have', 'the', 'good', 'sens', 'to', 'employ', 'a', 'laugh-track', 'so', 'that', 'the', 'audienc', 'will', 'be', 'signal', 'whenev', 'someth', 'is', 'broadcast', 'that', 'wa', 'intend', 'to', 'be', 'funny.', 'the', 'program', 'amount', 'to', 'a', 'scandal', 'wast', 'of', 'talent.']\n"
     ]
    }
   ],
   "source": [
    "print(words)\n",
    "print('\\n', stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing the Text : removing punt, Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "import re\n",
    "\n",
    "def text_to_words( raw_text ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw row text), and \n",
    "    # the output is a single string (a preprocessed row text)\n",
    "    #\n",
    "    # Remove HTML review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 1. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_text) \n",
    "    #\n",
    "    # 2. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 3. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 4. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 5. Stemming of the text\n",
    "    from nltk.stem import PorterStemmer\n",
    "    stemmed_words = []\n",
    "    for w in meaningful_words:\n",
    "        w = PorterStemmer().stem(w)\n",
    "        stemmed_words.append(w)\n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join(stemmed_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a List of the all the pre-processes text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "num_texts = itrain[0].size\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "cleaned_texts = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "for i in range( 0, num_texts ):\n",
    "    # Call our function for each one, and add the result to the list\n",
    "    cleaned_texts.append(text_to_words( itrain[0][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like this show.  The characters are fun and unique.  They dont have the typical skinny blond detective showing her ****. I hope they dont replace kate with one.  She is going to be though to replace.\n",
      "\n",
      "\n",
      " like show charact fun uniqu dont typic skinni blond detect show hope dont replac kate one go though replac\n"
     ]
    }
   ],
   "source": [
    "print(itrain[0][num_texts-1])\n",
    "\n",
    "print('\\n\\n', cleaned_texts[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bag of Words from the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "Done with bow creation\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the bag of words...\\n\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data into \n",
    "# feature vectors. The input to fit_transform should be a list of strings.\n",
    "train_data_features = vectorizer.fit_transform(cleaned_texts)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an array\n",
    "train_data = train_data_features.toarray()\n",
    "\n",
    "print('Done with bow creation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating td_idf from the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating td_idf from the bag of words ...\n",
      "\n",
      " Done with td_idf...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating td_idf from the bag of words ...\\n\")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer().fit(train_data_features)\n",
    "train_texts_tfidf = tfidf_transformer.transform(train_data_features)\n",
    "\n",
    "print(\" Done with td_idf...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\\'m not liking this new season.  I really didn\\'t like the fact that they changed the theme song.  It seems that the producers are trying to turn this show into another soap opera.  I\\'d rather watch the old seasons than this new season.  They were lively and they had better directing.\n",
      "\n",
      "   (0, 132)\t1\n",
      "  (0, 501)\t1\n",
      "  (0, 835)\t1\n",
      "  (0, 959)\t2\n",
      "  (0, 1003)\t1\n",
      "  (0, 1008)\t1\n",
      "  (0, 1143)\t1\n",
      "  (0, 1241)\t2\n",
      "  (0, 1284)\t1\n",
      "  (0, 1314)\t1\n",
      "  (0, 1324)\t1\n",
      "  (0, 1429)\t2\n",
      "  (0, 1430)\t1\n",
      "  (0, 1482)\t1\n",
      "  (0, 1546)\t1\n",
      "\n",
      "   (0, 1546)\t0.12268141323149433\n",
      "  (0, 1482)\t0.18832982106144547\n",
      "  (0, 1430)\t0.24689549364007543\n",
      "  (0, 1429)\t0.555216296853237\n",
      "  (0, 1324)\t0.2776081484266185\n",
      "  (0, 1314)\t0.20207247415230234\n",
      "  (0, 1284)\t0.06261956492081695\n",
      "  (0, 1241)\t0.28129432915843233\n",
      "  (0, 1143)\t0.22209948062870385\n",
      "  (0, 1008)\t0.22209948062870385\n",
      "  (0, 1003)\t0.19467047559148148\n",
      "  (0, 959)\t0.35571134386902087\n",
      "  (0, 835)\t0.13410556188275247\n",
      "  (0, 501)\t0.2596423970788967\n",
      "  (0, 132)\t0.17558291762262423\n"
     ]
    }
   ],
   "source": [
    "### Simple Example\n",
    "text4 = itrain[0][5]\n",
    "bow4 = vectorizer.transform([text4])\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(text4)\n",
    "print('\\n', bow4)\n",
    "print('\\n',tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for tag, count in zip(vocab, dist):\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 2)\n",
      "Cleaning and parsing the test set ...\n",
      "\n",
      "Done with Transforming of test data ...\n"
     ]
    }
   ],
   "source": [
    "#############   CLEANING THE TEST DATA & TRANSFORMING IT\n",
    "\n",
    "# Verify that there are 25,000 rows and 2 columns\n",
    "print(itest.shape)\n",
    "\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_test_texts = len(itest[0])\n",
    "clean_test_texts = [] \n",
    "\n",
    "print(\"Cleaning and parsing the test set ...\\n\")\n",
    "for i in range(0,num_test_texts):\n",
    "    clean_test_text = text_to_words( itest[0][i] )\n",
    "    clean_test_texts.append( clean_test_text )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_texts)\n",
    "test_data = test_data_features.toarray()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "test_texts_tfidf = tfidf_transformer.transform(test_data_features)\n",
    "\n",
    "print (\"Done with Transforming of test data ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "report on test data using random forest: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.75      0.68      0.71        40\n",
      "        pos       0.71      0.78      0.74        41\n",
      "\n",
      "avg / total       0.73      0.73      0.73        81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[27, 13],\n",
       "       [ 9, 32]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 200) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "\n",
    "forest = forest.fit( train_texts_tfidf, itrain[1] )\n",
    "\n",
    "# Predicting\n",
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_texts_tfidf)\n",
    "\n",
    "print('done')\n",
    "\n",
    "y_test = itest[1]\n",
    "\n",
    "output = pd.DataFrame(data= result)\n",
    "\n",
    "#train score\n",
    "from sklearn.metrics import classification_report\n",
    "print('report on test data using random forest: \\n', classification_report(y_test, output))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report on test data using Naves Bayes: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.81      0.55      0.66        40\n",
      "        pos       0.67      0.88      0.76        41\n",
      "\n",
      "avg / total       0.74      0.72      0.71        81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22, 18],\n",
       "       [ 5, 36]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB().fit(train_texts_tfidf, itrain[1]) # NB\n",
    "\n",
    "# Fit to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "\n",
    "nb_model_results = nb_model.predict(test_texts_tfidf)\n",
    "\n",
    "y_test = itest[1]\n",
    "\n",
    "output = pd.DataFrame( data = nb_model_results )\n",
    "\n",
    "#train score\n",
    "from sklearn.metrics import classification_report\n",
    "print('report on test data using Naves Bayes: \\n', classification_report(y_test, output))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/sa05975666/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package subjectivity to\n",
      "[nltk_data]     /home/sa05975666/nltk_data...\n",
      "[nltk_data]   Package subjectivity is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('subjectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para1: {'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'compound': 0.4927}\n",
      "para2: {'neg': 0.649, 'neu': 0.351, 'pos': 0.0, 'compound': -0.5719}\n",
      "\n",
      "para3: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "para4: {'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'compound': 0.4939}\n",
      "para5: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "### Polarity & Subjectivity\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "para1 = 'It is very good movie(pos)'\n",
    "para2 = 'I hate you (neg)'\n",
    "\n",
    "para3 = 'he went to the shop yesterday(obj)'\n",
    "para4 =  \"My girl friend has a phone(obj)\"\n",
    "para5 = 'I am not having a phone. So, I bought a phone(obj)'\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "ss = sid.polarity_scores(para1)\n",
    "print('para1:', ss)\n",
    "\n",
    "ss = sid.polarity_scores(para2)\n",
    "print('para2:',ss)\n",
    "\n",
    "ss = sid.polarity_scores(para3)\n",
    "print('\\npara3:',ss)\n",
    "\n",
    "ss = sid.polarity_scores(para4)\n",
    "print('para4:',ss)\n",
    "\n",
    "ss = sid.polarity_scores(para5)\n",
    "print('para5:', ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para1: Sentiment(polarity=0.9099999999999999, subjectivity=0.7800000000000001)\n",
      "para2: Sentiment(polarity=-0.8, subjectivity=0.9)\n",
      "\n",
      "para3: Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "para4: Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "para5: Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "print('para1:',TextBlob(para1).sentiment)\n",
    "print('para2:',TextBlob(para2).sentiment)\n",
    "print('\\npara3:',TextBlob(para3).sentiment)\n",
    "print('para4:',TextBlob(para4).sentiment)\n",
    "print('para5:',TextBlob(para5).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import subjectivity\n",
    "\n",
    "n_instances = 10\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.4019, 'neg': 0.0, 'neu': 0.0, 'pos': 1.0}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = sid.polarity_scores(subj_docs[0][0][0])\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = sid.polarity_scores(obj_docs[0][0][0])\n",
    "ss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
