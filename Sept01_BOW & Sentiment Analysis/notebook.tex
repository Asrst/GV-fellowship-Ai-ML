
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{nlp\_sentiAnlysis\_usecase}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{}import libraries}
        \PY{k+kn}{import} \PY{n+nn}{os}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{scipy} \PY{k}{as} \PY{n+nn}{sp}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k}{as} \PY{n+nn}{sns}
        \PY{k+kn}{import} \PY{n+nn}{math} \PY{k}{as} \PY{n+nn}{m}
        \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k}{import} \PY{n}{datasets}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{path} \PY{o}{=} \PY{n}{os}\PY{o}{.}\PY{n}{getcwd}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{itrain} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}excel}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{path}\PY{p}{)}\PY{o}{+}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/nlp\PYZus{}train.xlsx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header} \PY{o}{=} \PY{k+kc}{None}\PY{p}{)}
         \PY{n}{itest} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}excel}\PY{p}{(}\PY{n+nb}{str}\PY{p}{(}\PY{n}{path}\PY{p}{)}\PY{o}{+}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/nlp\PYZus{}test.xlsx}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{header} \PY{o}{=} \PY{k+kc}{None}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{n}{itrain}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
         \PY{n}{itrain}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}14}]:} (386, 2)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n}{itest}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
         \PY{n}{itest}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}15}]:} (81, 2)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{itrain}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{itest}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
neg    194
pos    192
Name: 1, dtype: int64

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}17}]:} pos    41
         neg    40
         Name: 1, dtype: int64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{n}{itrain}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{any}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}47}]:} 0    False
         1    False
         dtype: bool
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}166}]:} \PY{n}{itrain}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{n}{itrain}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}166}]:}         0                                                               
              count unique                                                top freq
          1                                                                       
          neg   194    194  Laugh track does not help this show in the lea{\ldots}    1
          pos   192    192  This show is the best legal show in years. The{\ldots}    1
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} 
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Not Everybody loves Raymond.  The only joke here is that the idea actually found its way onto the airwaves.  In other words it\textbackslash{}'s just one joke less than a one joke program.  As with most sitcoms, it appeals to those with an intellectual development that was stopped at age 8.  Fortunately they did have the good sense to employ a laugh-track so that the audience will be signaled whenever something is broadcast that was intended to be funny. The program amounts to a scandalous waste of talent.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}144}]:} \PY{n}{words} \PY{o}{=} \PY{n}{itrain}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}
          
          \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{stem} \PY{k}{import} \PY{n}{PorterStemmer}
          \PY{n}{stemmed\PYZus{}words} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          \PY{k}{for} \PY{n}{w} \PY{o+ow}{in} \PY{n}{words}\PY{p}{:}
              \PY{n}{w} \PY{o}{=} \PY{n}{PorterStemmer}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{stem}\PY{p}{(}\PY{n}{w}\PY{p}{)} 
              \PY{n}{stemmed\PYZus{}words}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{w}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}146}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{words}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{stemmed\PYZus{}words}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
['not', 'everybody', 'loves', 'raymond.', 'the', 'only', 'joke', 'here', 'is', 'that', 'the', 'idea', 'actually', 'found', 'its', 'way', 'onto', 'the', 'airwaves.', 'in', 'other', 'words', "it\textbackslash{}\textbackslash{}'s", 'just', 'one', 'joke', 'less', 'than', 'a', 'one', 'joke', 'program.', 'as', 'with', 'most', 'sitcoms,', 'it', 'appeals', 'to', 'those', 'with', 'an', 'intellectual', 'development', 'that', 'was', 'stopped', 'at', 'age', '8.', 'fortunately', 'they', 'did', 'have', 'the', 'good', 'sense', 'to', 'employ', 'a', 'laugh-track', 'so', 'that', 'the', 'audience', 'will', 'be', 'signaled', 'whenever', 'something', 'is', 'broadcast', 'that', 'was', 'intended', 'to', 'be', 'funny.', 'the', 'program', 'amounts', 'to', 'a', 'scandalous', 'waste', 'of', 'talent.']

 ['not', 'everybodi', 'love', 'raymond.', 'the', 'onli', 'joke', 'here', 'is', 'that', 'the', 'idea', 'actual', 'found', 'it', 'way', 'onto', 'the', 'airwaves.', 'in', 'other', 'word', "it\textbackslash{}\textbackslash{}'", 'just', 'one', 'joke', 'less', 'than', 'a', 'one', 'joke', 'program.', 'as', 'with', 'most', 'sitcoms,', 'it', 'appeal', 'to', 'those', 'with', 'an', 'intellectu', 'develop', 'that', 'wa', 'stop', 'at', 'age', '8.', 'fortun', 'they', 'did', 'have', 'the', 'good', 'sens', 'to', 'employ', 'a', 'laugh-track', 'so', 'that', 'the', 'audienc', 'will', 'be', 'signal', 'whenev', 'someth', 'is', 'broadcast', 'that', 'wa', 'intend', 'to', 'be', 'funny.', 'the', 'program', 'amount', 'to', 'a', 'scandal', 'wast', 'of', 'talent.']

    \end{Verbatim}

    \subsubsection{Pre-Processing the Text : removing punt,
Stopwords}\label{pre-processing-the-text-removing-punt-stopwords}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}147}]:} \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{corpus} \PY{k}{import} \PY{n}{stopwords} \PY{c+c1}{\PYZsh{} Import the stop word list}
          \PY{k+kn}{import} \PY{n+nn}{re}
          
          \PY{k}{def} \PY{n+nf}{text\PYZus{}to\PYZus{}words}\PY{p}{(} \PY{n}{raw\PYZus{}text} \PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} Function to convert a raw review to a string of words}
              \PY{c+c1}{\PYZsh{} The input is a single string (a raw row text), and }
              \PY{c+c1}{\PYZsh{} the output is a single string (a preprocessed row text)}
              \PY{c+c1}{\PYZsh{}}
              \PY{c+c1}{\PYZsh{} Remove HTML review\PYZus{}text = BeautifulSoup(raw\PYZus{}review).get\PYZus{}text() }
              \PY{c+c1}{\PYZsh{}}
              \PY{c+c1}{\PYZsh{} 1. Remove non\PYZhy{}letters        }
              \PY{n}{letters\PYZus{}only} \PY{o}{=} \PY{n}{re}\PY{o}{.}\PY{n}{sub}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{[\PYZca{}a\PYZhy{}zA\PYZhy{}Z]}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{raw\PYZus{}text}\PY{p}{)} 
              \PY{c+c1}{\PYZsh{}}
              \PY{c+c1}{\PYZsh{} 2. Convert to lower case, split into individual words}
              \PY{n}{words} \PY{o}{=} \PY{n}{letters\PYZus{}only}\PY{o}{.}\PY{n}{lower}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{p}{)}                             
              \PY{c+c1}{\PYZsh{}}
              \PY{c+c1}{\PYZsh{} 3. In Python, searching a set is much faster than searching}
              \PY{c+c1}{\PYZsh{}   a list, so convert the stop words to a set}
              \PY{n}{stops} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{n}{stopwords}\PY{o}{.}\PY{n}{words}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{english}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}                  
              \PY{c+c1}{\PYZsh{} }
              \PY{c+c1}{\PYZsh{} 4. Remove stop words}
              \PY{n}{meaningful\PYZus{}words} \PY{o}{=} \PY{p}{[}\PY{n}{w} \PY{k}{for} \PY{n}{w} \PY{o+ow}{in} \PY{n}{words} \PY{k}{if} \PY{o+ow}{not} \PY{n}{w} \PY{o+ow}{in} \PY{n}{stops}\PY{p}{]}   
              \PY{c+c1}{\PYZsh{}}
              \PY{c+c1}{\PYZsh{} 5. Stemming of the text}
              \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{stem} \PY{k}{import} \PY{n}{PorterStemmer}
              \PY{n}{stemmed\PYZus{}words} \PY{o}{=} \PY{p}{[}\PY{p}{]}
              \PY{k}{for} \PY{n}{w} \PY{o+ow}{in} \PY{n}{meaningful\PYZus{}words}\PY{p}{:}
                  \PY{n}{w} \PY{o}{=} \PY{n}{PorterStemmer}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{stem}\PY{p}{(}\PY{n}{w}\PY{p}{)}
                  \PY{n}{stemmed\PYZus{}words}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{w}\PY{p}{)}
              \PY{c+c1}{\PYZsh{}}
              \PY{c+c1}{\PYZsh{} 6. Join the words back into one string separated by space, }
              \PY{c+c1}{\PYZsh{} and return the result.}
              \PY{k}{return}\PY{p}{(} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ }\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{join}\PY{p}{(}\PY{n}{stemmed\PYZus{}words}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Creating a List of the all the pre-processes
text}\label{creating-a-list-of-the-all-the-pre-processes-text}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}148}]:} \PY{c+c1}{\PYZsh{} Get the number of reviews based on the dataframe column size}
          \PY{n}{num\PYZus{}texts} \PY{o}{=} \PY{n}{itrain}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{size}
          
          \PY{c+c1}{\PYZsh{} Initialize an empty list to hold the clean reviews}
          \PY{n}{cleaned\PYZus{}texts} \PY{o}{=} \PY{p}{[}\PY{p}{]}
          
          \PY{c+c1}{\PYZsh{} Loop over each review; create an index i that goes from 0 to the length}
          \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{num\PYZus{}texts} \PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} Call our function for each one, and add the result to the list}
              \PY{n}{cleaned\PYZus{}texts}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{text\PYZus{}to\PYZus{}words}\PY{p}{(} \PY{n}{itrain}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}149}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{itrain}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{n}{num\PYZus{}texts}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cleaned\PYZus{}texts}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
I like this show.  The characters are fun and unique.  They dont have the typical skinny blond detective showing her ****. I hope they dont replace kate with one.  She is going to be though to replace.


 like show charact fun uniqu dont typic skinni blond detect show hope dont replac kate one go though replac

    \end{Verbatim}

    \subsubsection{Creating Bag of Words from the cleaned
text}\label{creating-bag-of-words-from-the-cleaned-text}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}150}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Creating the bag of words...}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}extraction}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{CountVectorizer}
          
          \PY{c+c1}{\PYZsh{} Initialize the \PYZdq{}CountVectorizer\PYZdq{} object, which is scikit\PYZhy{}learn\PYZsq{}s}
          \PY{c+c1}{\PYZsh{} bag of words tool.  }
          \PY{n}{vectorizer} \PY{o}{=} \PY{n}{CountVectorizer}\PY{p}{(}\PY{n}{analyzer} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{word}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,}   \PYZbs{}
                                       \PY{n}{tokenizer} \PY{o}{=} \PY{k+kc}{None}\PY{p}{,}    \PYZbs{}
                                       \PY{n}{preprocessor} \PY{o}{=} \PY{k+kc}{None}\PY{p}{,} \PYZbs{}
                                       \PY{n}{stop\PYZus{}words} \PY{o}{=} \PY{k+kc}{None}\PY{p}{,}   \PYZbs{}
                                       \PY{n}{max\PYZus{}features} \PY{o}{=} \PY{l+m+mi}{5000}\PY{p}{)} 
          
          \PY{c+c1}{\PYZsh{} fit\PYZus{}transform() does two functions: First, it fits the model}
          \PY{c+c1}{\PYZsh{} and learns the vocabulary; second, it transforms our training data into }
          \PY{c+c1}{\PYZsh{} feature vectors. The input to fit\PYZus{}transform should be a list of strings.}
          \PY{n}{train\PYZus{}data\PYZus{}features} \PY{o}{=} \PY{n}{vectorizer}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{cleaned\PYZus{}texts}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Numpy arrays are easy to work with, so convert the result to an array}
          \PY{n}{train\PYZus{}data} \PY{o}{=} \PY{n}{train\PYZus{}data\PYZus{}features}\PY{o}{.}\PY{n}{toarray}\PY{p}{(}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Done with bow creation}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Creating the bag of words{\ldots}

Done with bow creation

    \end{Verbatim}

    \subsubsection{Creating td\_idf from the cleaned
text}\label{creating-td_idf-from-the-cleaned-text}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}151}]:} \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Creating td\PYZus{}idf from the bag of words ...}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}extraction}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{TfidfTransformer}
          \PY{n}{tfidf\PYZus{}transformer} \PY{o}{=} \PY{n}{TfidfTransformer}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train\PYZus{}data\PYZus{}features}\PY{p}{)}
          \PY{n}{train\PYZus{}texts\PYZus{}tfidf} \PY{o}{=} \PY{n}{tfidf\PYZus{}transformer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{train\PYZus{}data\PYZus{}features}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ Done with td\PYZus{}idf...}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Creating td\_idf from the bag of words {\ldots}

 Done with td\_idf{\ldots}


    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}162}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Simple Example}
          \PY{n}{text4} \PY{o}{=} \PY{n}{itrain}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}
          \PY{n}{bow4} \PY{o}{=} \PY{n}{vectorizer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{p}{[}\PY{n}{text4}\PY{p}{]}\PY{p}{)}
          \PY{n}{tfidf4} \PY{o}{=} \PY{n}{tfidf\PYZus{}transformer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{bow4}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{text4}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bow4}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{tfidf4}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
I\textbackslash{}'m not liking this new season.  I really didn\textbackslash{}'t like the fact that they changed the theme song.  It seems that the producers are trying to turn this show into another soap opera.  I\textbackslash{}'d rather watch the old seasons than this new season.  They were lively and they had better directing.

   (0, 132)	1
  (0, 501)	1
  (0, 835)	1
  (0, 959)	2
  (0, 1003)	1
  (0, 1008)	1
  (0, 1143)	1
  (0, 1241)	2
  (0, 1284)	1
  (0, 1314)	1
  (0, 1324)	1
  (0, 1429)	2
  (0, 1430)	1
  (0, 1482)	1
  (0, 1546)	1

   (0, 1546)	0.12268141323149433
  (0, 1482)	0.18832982106144547
  (0, 1430)	0.24689549364007543
  (0, 1429)	0.555216296853237
  (0, 1324)	0.2776081484266185
  (0, 1314)	0.20207247415230234
  (0, 1284)	0.06261956492081695
  (0, 1241)	0.28129432915843233
  (0, 1143)	0.22209948062870385
  (0, 1008)	0.22209948062870385
  (0, 1003)	0.19467047559148148
  (0, 959)	0.35571134386902087
  (0, 835)	0.13410556188275247
  (0, 501)	0.2596423970788967
  (0, 132)	0.17558291762262423

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}110}]:} \PY{c+c1}{\PYZsh{} Take a look at the words in the vocabulary}
          \PY{n}{vocab} \PY{o}{=} \PY{n}{vectorizer}\PY{o}{.}\PY{n}{get\PYZus{}feature\PYZus{}names}\PY{p}{(}\PY{p}{)}
          
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          
          \PY{c+c1}{\PYZsh{} Sum up the counts of each vocabulary word}
          \PY{n}{dist} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{n}{train\PYZus{}data}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} For each, print the vocabulary word and the number of times it }
          \PY{c+c1}{\PYZsh{} appears in the training set}
          \PY{k}{for} \PY{n}{tag}\PY{p}{,} \PY{n}{count} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{vocab}\PY{p}{,} \PY{n}{dist}\PY{p}{)}\PY{p}{:}
              \PY{n+nb}{print}\PY{p}{(}\PY{n}{count}\PY{p}{,} \PY{n}{tag}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}164}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}\PYZsh{}   CLEANING THE TEST DATA \PYZam{} TRANSFORMING IT}
          
          \PY{c+c1}{\PYZsh{} Verify that there are 25,000 rows and 2 columns}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{itest}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Create an empty list and append the clean reviews one by one}
          \PY{n}{num\PYZus{}test\PYZus{}texts} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{itest}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
          \PY{n}{clean\PYZus{}test\PYZus{}texts} \PY{o}{=} \PY{p}{[}\PY{p}{]} 
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Cleaning and parsing the test set ...}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
          \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{n}{num\PYZus{}test\PYZus{}texts}\PY{p}{)}\PY{p}{:}
              \PY{n}{clean\PYZus{}test\PYZus{}text} \PY{o}{=} \PY{n}{text\PYZus{}to\PYZus{}words}\PY{p}{(} \PY{n}{itest}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{p}{)}
              \PY{n}{clean\PYZus{}test\PYZus{}texts}\PY{o}{.}\PY{n}{append}\PY{p}{(} \PY{n}{clean\PYZus{}test\PYZus{}text} \PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Get a bag of words for the test set, and convert to a numpy array}
          \PY{n}{test\PYZus{}data\PYZus{}features} \PY{o}{=} \PY{n}{vectorizer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{clean\PYZus{}test\PYZus{}texts}\PY{p}{)}
          \PY{n}{test\PYZus{}data} \PY{o}{=} \PY{n}{test\PYZus{}data\PYZus{}features}\PY{o}{.}\PY{n}{toarray}\PY{p}{(}\PY{p}{)}
          
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{feature\PYZus{}extraction}\PY{n+nn}{.}\PY{n+nn}{text} \PY{k}{import} \PY{n}{TfidfTransformer}
          \PY{n}{test\PYZus{}texts\PYZus{}tfidf} \PY{o}{=} \PY{n}{tfidf\PYZus{}transformer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{test\PYZus{}data\PYZus{}features}\PY{p}{)}
          
          \PY{n+nb}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Done with Transforming of test data ...}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(81, 2)
Cleaning and parsing the test set {\ldots}

Done with Transforming of test data {\ldots}

    \end{Verbatim}

    \subsubsection{Model Building}\label{model-building}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}156}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{ensemble} \PY{k}{import} \PY{n}{RandomForestClassifier}
          
          \PY{c+c1}{\PYZsh{} Initialize a Random Forest classifier with 100 trees}
          \PY{n}{forest} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators} \PY{o}{=} \PY{l+m+mi}{200}\PY{p}{)} 
          
          \PY{c+c1}{\PYZsh{} Fit the forest to the training set, using the bag of words as }
          \PY{c+c1}{\PYZsh{} features and the sentiment labels as the response variable}
          
          \PY{n}{forest} \PY{o}{=} \PY{n}{forest}\PY{o}{.}\PY{n}{fit}\PY{p}{(} \PY{n}{train\PYZus{}texts\PYZus{}tfidf}\PY{p}{,} \PY{n}{itrain}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Predicting}
          \PY{c+c1}{\PYZsh{} Use the random forest to make sentiment label predictions}
          \PY{n}{result} \PY{o}{=} \PY{n}{forest}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}texts\PYZus{}tfidf}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{done}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{itest}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
          
          \PY{n}{output} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{data}\PY{o}{=} \PY{n}{result}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{}train score}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{classification\PYZus{}report}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{report on test data using random forest: }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{output}\PY{p}{)}\PY{p}{)}
          
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{confusion\PYZus{}matrix}
          \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{output}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
done
report on test data using random forest: 
              precision    recall  f1-score   support

        neg       0.75      0.68      0.71        40
        pos       0.71      0.78      0.74        41

avg / total       0.73      0.73      0.73        81


    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}156}]:} array([[27, 13],
                 [ 9, 32]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}160}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{naive\PYZus{}bayes} \PY{k}{import} \PY{n}{MultinomialNB}
          
          \PY{n}{nb\PYZus{}model} \PY{o}{=} \PY{n}{MultinomialNB}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train\PYZus{}texts\PYZus{}tfidf}\PY{p}{,} \PY{n}{itrain}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)} \PY{c+c1}{\PYZsh{} NB}
          
          \PY{c+c1}{\PYZsh{} Fit to the training set, using the bag of words as }
          \PY{c+c1}{\PYZsh{} features and the sentiment labels as the response variable}
          
          \PY{n}{nb\PYZus{}model\PYZus{}results} \PY{o}{=} \PY{n}{nb\PYZus{}model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{test\PYZus{}texts\PYZus{}tfidf}\PY{p}{)}
          
          \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{itest}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
          
          \PY{n}{output} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(} \PY{n}{data} \PY{o}{=} \PY{n}{nb\PYZus{}model\PYZus{}results} \PY{p}{)}
          
          \PY{c+c1}{\PYZsh{}train score}
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{classification\PYZus{}report}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{report on test data using Naves Bayes: }\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{output}\PY{p}{)}\PY{p}{)}
          
          \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{metrics} \PY{k}{import} \PY{n}{confusion\PYZus{}matrix}
          \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{output}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
report on test data using Naves Bayes: 
              precision    recall  f1-score   support

        neg       0.81      0.55      0.66        40
        pos       0.67      0.88      0.76        41

avg / total       0.74      0.72      0.71        81


    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}160}]:} array([[22, 18],
                 [ 5, 36]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}182}]:} \PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{vader\PYZus{}lexicon}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{nltk}\PY{o}{.}\PY{n}{download}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subjectivity}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[nltk\_data] Downloading package vader\_lexicon to
[nltk\_data]     /home/sa05975666/nltk\_data{\ldots}
[nltk\_data]   Package vader\_lexicon is already up-to-date!
[nltk\_data] Downloading package subjectivity to
[nltk\_data]     /home/sa05975666/nltk\_data{\ldots}
[nltk\_data]   Package subjectivity is already up-to-date!

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}182}]:} True
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}292}]:} \PY{c+c1}{\PYZsh{}\PYZsh{}\PYZsh{} Polarity \PYZam{} Subjectivity}
          
          \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{sentiment}\PY{n+nn}{.}\PY{n+nn}{vader} \PY{k}{import} \PY{n}{SentimentIntensityAnalyzer}
          
          \PY{n}{para1} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{It is very good movie(pos)}\PY{l+s+s1}{\PYZsq{}}
          \PY{n}{para2} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I hate you (neg)}\PY{l+s+s1}{\PYZsq{}}
          
          \PY{n}{para3} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{he went to the shop yesterday(obj)}\PY{l+s+s1}{\PYZsq{}}
          \PY{n}{para4} \PY{o}{=}  \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{My girl friend has a phone(obj)}\PY{l+s+s2}{\PYZdq{}}
          \PY{n}{para5} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{I am not having a phone. So, I bought a phone(obj)}\PY{l+s+s1}{\PYZsq{}}
          
          \PY{n}{sid} \PY{o}{=} \PY{n}{SentimentIntensityAnalyzer}\PY{p}{(}\PY{p}{)}
          \PY{n}{ss} \PY{o}{=} \PY{n}{sid}\PY{o}{.}\PY{n}{polarity\PYZus{}scores}\PY{p}{(}\PY{n}{para1}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{para1:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ss}\PY{p}{)}
          
          \PY{n}{ss} \PY{o}{=} \PY{n}{sid}\PY{o}{.}\PY{n}{polarity\PYZus{}scores}\PY{p}{(}\PY{n}{para2}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{para2:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{ss}\PY{p}{)}
          
          \PY{n}{ss} \PY{o}{=} \PY{n}{sid}\PY{o}{.}\PY{n}{polarity\PYZus{}scores}\PY{p}{(}\PY{n}{para3}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{para3:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{ss}\PY{p}{)}
          
          \PY{n}{ss} \PY{o}{=} \PY{n}{sid}\PY{o}{.}\PY{n}{polarity\PYZus{}scores}\PY{p}{(}\PY{n}{para4}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{para4:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{ss}\PY{p}{)}
          
          \PY{n}{ss} \PY{o}{=} \PY{n}{sid}\PY{o}{.}\PY{n}{polarity\PYZus{}scores}\PY{p}{(}\PY{n}{para5}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{para5:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ss}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
para1: \{'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'compound': 0.4927\}
para2: \{'neg': 0.649, 'neu': 0.351, 'pos': 0.0, 'compound': -0.5719\}

para3: \{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0\}
para4: \{'neg': 0.0, 'neu': 0.556, 'pos': 0.444, 'compound': 0.4939\}
para5: \{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0\}

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}293}]:} \PY{k+kn}{from} \PY{n+nn}{textblob} \PY{k}{import} \PY{n}{TextBlob}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{para1:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{TextBlob}\PY{p}{(}\PY{n}{para1}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{para2:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{TextBlob}\PY{p}{(}\PY{n}{para2}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{para3:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{TextBlob}\PY{p}{(}\PY{n}{para3}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{para4:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{TextBlob}\PY{p}{(}\PY{n}{para4}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{para5:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{TextBlob}\PY{p}{(}\PY{n}{para5}\PY{p}{)}\PY{o}{.}\PY{n}{sentiment}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
para1: Sentiment(polarity=0.9099999999999999, subjectivity=0.7800000000000001)
para2: Sentiment(polarity=-0.8, subjectivity=0.9)

para3: Sentiment(polarity=0.0, subjectivity=0.0)
para4: Sentiment(polarity=0.0, subjectivity=0.0)
para5: Sentiment(polarity=0.0, subjectivity=0.0)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}183}]:} \PY{k+kn}{from} \PY{n+nn}{nltk}\PY{n+nn}{.}\PY{n+nn}{corpus} \PY{k}{import} \PY{n}{subjectivity}
          
          \PY{n}{n\PYZus{}instances} \PY{o}{=} \PY{l+m+mi}{10}
          \PY{n}{subj\PYZus{}docs} \PY{o}{=} \PY{p}{[}\PY{p}{(}\PY{n}{sent}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{for} \PY{n}{sent} \PY{o+ow}{in} \PY{n}{subjectivity}\PY{o}{.}\PY{n}{sents}\PY{p}{(}\PY{n}{categories}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{subj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{n}{n\PYZus{}instances}\PY{p}{]}\PY{p}{]}
          \PY{n}{obj\PYZus{}docs} \PY{o}{=} \PY{p}{[}\PY{p}{(}\PY{n}{sent}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{obj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{for} \PY{n}{sent} \PY{o+ow}{in} \PY{n}{subjectivity}\PY{o}{.}\PY{n}{sents}\PY{p}{(}\PY{n}{categories}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{obj}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{n}{n\PYZus{}instances}\PY{p}{]}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}188}]:} \PY{n}{ss} \PY{o}{=} \PY{n}{sid}\PY{o}{.}\PY{n}{polarity\PYZus{}scores}\PY{p}{(}\PY{n}{subj\PYZus{}docs}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
          \PY{n}{ss}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}188}]:} \{'compound': 0.4019, 'neg': 0.0, 'neu': 0.0, 'pos': 1.0\}
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}189}]:} \PY{n}{ss} \PY{o}{=} \PY{n}{sid}\PY{o}{.}\PY{n}{polarity\PYZus{}scores}\PY{p}{(}\PY{n}{obj\PYZus{}docs}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
          \PY{n}{ss}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}189}]:} \{'compound': 0.0, 'neg': 0.0, 'neu': 1.0, 'pos': 0.0\}
\end{Verbatim}
            

    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
