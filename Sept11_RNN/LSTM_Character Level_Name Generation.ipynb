{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/usr/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fn = pd.read_csv('Indian-Female-Names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = fn.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fn['name'].tolist()\n",
    "raw_names = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "names_only =[]\n",
    "\n",
    "for i in range(0,len(raw_names)):\n",
    "    processed_name = re.sub(\"[^a-zA-Z]\", \" \", raw_names[i])\n",
    "    name = processed_name.lower()\n",
    "    names_only.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shivani',\n",
       " 'isha',\n",
       " 'smt shyani devi',\n",
       " 'divya',\n",
       " 'mansi',\n",
       " 'mazida',\n",
       " 'pooja',\n",
       " 'kajal',\n",
       " 'meena',\n",
       " 'sonam']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_only[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(all_names_list):\n",
    "    return(\"\\n\".join(all_names_list))\n",
    "\n",
    "nameString = process(names_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_letters = set(nameString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(unique_letters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '\\n'), (1, ' '), (2, 'a'), (3, 'b'), (4, 'c'), (5, 'd'), (6, 'e'), (7, 'f'), (8, 'g'), (9, 'h'), (10, 'i'), (11, 'j'), (12, 'k'), (13, 'l'), (14, 'm'), (15, 'n'), (16, 'o'), (17, 'p'), (18, 'q'), (19, 'r'), (20, 's'), (21, 't'), (22, 'u'), (23, 'v'), (24, 'w'), (25, 'x'), (26, 'y'), (27, 'z')]\n"
     ]
    }
   ],
   "source": [
    "print(list(enumerate(chars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27}\n"
     ]
    }
   ],
   "source": [
    "index_to_char = {i:c for i,c in enumerate(chars)}\n",
    "char_to_index = {c:i for i,c in enumerate(chars)}\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shivani\n",
      "is ---> h\n",
      "hivani\n",
      "ish ---> a\n",
      "ivani\n",
      "isha ---> \n",
      "\n",
      "vani\n",
      "isha\n",
      " ---> s\n",
      "ani\n",
      "isha\n",
      "s ---> m\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, len(nameString)-seq_len, 1):\n",
    "    seq_in = nameString[i:i+seq_len]\n",
    "    seq_out = nameString[i+seq_len]\n",
    "    dataX.append([char_to_index[char] for char in seq_in])\n",
    "    dataY.append(char_to_index[seq_out])\n",
    "    if i < 5:\n",
    "        print(seq_in, '--->', seq_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144820\n",
      "144820\n"
     ]
    }
   ],
   "source": [
    "print(len(dataX))\n",
    "print(len(dataY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144830"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nameString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144820, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "\n",
    "Xi = np.reshape(dataX, (len(dataX), seq_len, 1))  #reshape to (samples, time_steps, features)\n",
    "X = Xi/float(len(text))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144820, 28)\n"
     ]
    }
   ],
   "source": [
    "y = np_utils.to_categorical(dataY)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences :  28960\n",
      "Unique characters:  28\n",
      "Doing Vectorization\n"
     ]
    }
   ],
   "source": [
    "text=nameString\n",
    "\n",
    "maxlen = 30\n",
    "step = 5\n",
    "sentences=[]\n",
    "next_chars=[]\n",
    "for i in range(0,len(text)-maxlen,step):\n",
    "    sentences.append(text[i:i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "print('Number of sequences : ',len(sentences))\n",
    "\n",
    "chars=sorted(list(set(text)))\n",
    "print('Unique characters: ',len(chars))\n",
    "\n",
    "char_indices=dict((char,chars.index(char)) for char in chars)\n",
    "\n",
    "print(\"Doing Vectorization\")\n",
    "x=np.zeros((len(sentences),maxlen,len(chars)),dtype=np.bool)\n",
    "y=np.zeros((len(sentences),len(chars)),dtype=np.bool)\n",
    "\n",
    "for i,sentence in enumerate(sentences):\n",
    "    for t,char in enumerate(sentence):\n",
    "        x[i,t,char_indices[char]]=1\n",
    "    y[i,char_indices[next_chars[i]]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(layers.LSTM(256,input_shape=(maxlen,len(chars))))\n",
    "model.add(layers.Dense(len(chars),activation='softmax'))\n",
    "optimize = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer = optimize, metrics = ['accuracy'])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, randomness=1.0):\n",
    "    preds=np.asarray(preds).astype('float64')\n",
    "    preds=np.log(preds)/randomness\n",
    "    exp_preds=np.exp(preds)\n",
    "    preds=exp_preds/np.sum(exp_preds)\n",
    "    probas=np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Try  1\n",
      "Epoch 1/5\n",
      "28960/28960 [==============================] - 40s 1ms/step - loss: 1.9555 - acc: 0.4127\n",
      "Epoch 2/5\n",
      "28960/28960 [==============================] - 38s 1ms/step - loss: 1.9188 - acc: 0.4227\n",
      "Epoch 3/5\n",
      "28960/28960 [==============================] - 39s 1ms/step - loss: 1.8856 - acc: 0.4321\n",
      "Epoch 4/5\n",
      "28960/28960 [==============================] - 40s 1ms/step - loss: 1.8501 - acc: 0.4440\n",
      "Epoch 5/5\n",
      "28960/28960 [==============================] - 39s 1ms/step - loss: 1.8032 - acc: 0.4610\n",
      "---Generating with seed : \"ita\n",
      "annu\n",
      "preeti\n",
      "mamta\n",
      "rinki\n",
      "jy \"\n",
      "---randomness : 0.2\n",
      "ita\n",
      "annu\n",
      "preeti\n",
      "mamta\n",
      "rinki\n",
      "jyothmita monema\n",
      "madukhunni u suna sumrema deessha chankema\n",
      "smt mandeeta\n",
      "karhika deyarari shti\n",
      "kavemha---randomness : 0.5\n",
      "\n",
      "karhika deyarari shti\n",
      "kavemhajam\n",
      "susar\n",
      "umta\n",
      "mayanahanwati\n",
      "nesh  bau\n",
      "kamal kumari\n",
      "bimar\n",
      "ranu devi muma nehhun\n",
      "bazba\n",
      "pabobmimya\n",
      "jan---randomness : 1.0\n",
      "ma nehhun\n",
      "bazba\n",
      "pabobmimya\n",
      "janpana devi\n",
      "jish sheeth\n",
      "mandul\n",
      "reeta pangeshisan\n",
      "meetu natyi\n",
      "neha\n",
      "nil lekham\n",
      "kanup y rushajya\n",
      "sonu\n",
      "sav---randomness : 1.5\n",
      "kham\n",
      "kanup y rushajya\n",
      "sonu\n",
      "savima\n",
      "savglal\n",
      "yarjani\n",
      "anjabheran\n",
      "tamaha\n",
      "pabna\n",
      "chandheha guvi\n",
      "nisipan\n",
      "sunuta\n",
      "smishmte\n",
      "mamari jaiya\n",
      "smt "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for item in range(1,2):\n",
    "    print()\n",
    "    print('Try ',item)\n",
    "    model.fit(x,y,batch_size = 64, epochs = 10)\n",
    "    start_index=random.randint(0,len(text)-maxlen-1)\n",
    "    generated_text=text[start_index:start_index+maxlen]\n",
    "    \n",
    "    print('---Generating with seed : \"'+ generated_text +' \"')  \n",
    "    \n",
    "    for randomness in [0.2,0.5,1.0,1.5]:\n",
    "        print('---randomness :',randomness)\n",
    "        sys.stdout.write(generated_text)    \n",
    "        for i in range(100):\n",
    "            sampled=np.zeros((1,maxlen,len(chars)))\n",
    "            for t,char in enumerate(generated_text):\n",
    "                sampled[0,t,char_indices[char]]=1\n",
    "\n",
    "            preds=model.predict(sampled,verbose=0)[0]\n",
    "            next_index=sample(preds,temperature)\n",
    "            next_char=chars[next_index]\n",
    "\n",
    "            generated_text+=next_char\n",
    "            generated_text=generated_text[1:]\n",
    "            sys.stdout.write(next_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
